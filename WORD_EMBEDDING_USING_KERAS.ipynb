{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WORD EMBEDDING USING KERAS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxaP4k2SzH+//DFAuLD6fI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagu12/all-projects/blob/master/WORD_EMBEDDING_USING_KERAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2Z69MHY-FrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TumU6Di5VjdS",
        "colab_type": "text"
      },
      "source": [
        "#what is word embedding?\n",
        "the creation of words into a vector format and finding the cosine similarity of the words by looking at their vector values is called word embedding. it basically helps in preserving the semantic similarity of the words and also vectorizes the word in a proper way where we can actually prioritize the important words in a sentence.....\n",
        "\n",
        "#parameters to be used during coding of a word embedding model\n",
        "1. creation of word dictionary or find the vocabulary size containing sequence of words in proper order.\n",
        "2. Creating the word into one hot encoded vectors.\n",
        "3. Getting the index values of the words in the corpus of sentences.\n",
        "4. Passing the generated vectors through the embedding layer.\n",
        "5. This embedding layer will convert these vectors into some other vector representation based on feature selection criteria.\n",
        "6. Giving the desired dimensions in which we want to represent the particular word in vector representation.\n",
        "7. So embedding helps in creating a feature representation of particular words in the corpus.\n",
        "8. here the dimensions are the no. of features we are giving to keras vector form.\n",
        "9. vocab size is actually the size of our vector initially created so as to designate the words under specific numerical range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4IDaEbTuEIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNE0wfyZuYtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SENTENCES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcy6ItszudKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent= [\"the glass of milk\", \n",
        "\"the glass of juice\",\n",
        "\"the cup of tea\",\n",
        "\"I am a good boy\",\n",
        "\"I am a good developer\",\n",
        "\"understand the meaning of words\",\n",
        "\"your videos are good\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMs2Cha6vo5p",
        "colab_type": "code",
        "outputId": "62c0867d-9135-4d31-db27-9e327d15b671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "sent"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW3nAierwPS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocabulary size or the size of the dictionary\n",
        "voc_size= 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6oXic1Ywle9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot representation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3899A9aXG3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "64a41dc9-fd8e-4dc6-f321-d02f682af076"
      },
      "source": [
        "#getting the indexes from the dictionary\n",
        "onehot_repr= [one_hot(words,voc_size) for words in sent]\n",
        "print(onehot_repr)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7371, 713, 3825, 87], [7371, 713, 3825, 3482], [7371, 1056, 3825, 3630], [7440, 3361, 5867, 5639, 1672], [7440, 3361, 5867, 5639, 619], [4604, 7371, 3181, 3825, 4163], [6462, 1416, 699, 5639]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wox4yZmPwSRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word embedding representation and forming the embedding matrix with the desired dimensions/features we want to give "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfxWsi7Xcd2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ8GMvkOdv_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teUhUW-DeuWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#padding basically adds extra words in the form of 0 in pre or post position to make all the sentences of equal length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL2Vdl4jeSpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "63e2a01b-60e7-42e3-9523-ff1287f16039"
      },
      "source": [
        "sent_length= 8\n",
        "embedded_docs= pad_sequences(onehot_repr, padding=\"pre\", maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0 7371  713 3825   87]\n",
            " [   0    0    0    0 7371  713 3825 3482]\n",
            " [   0    0    0    0 7371 1056 3825 3630]\n",
            " [   0    0    0 7440 3361 5867 5639 1672]\n",
            " [   0    0    0 7440 3361 5867 5639  619]\n",
            " [   0    0    0 4604 7371 3181 3825 4163]\n",
            " [   0    0    0    0 6462 1416  699 5639]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fX6niUEe5vH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating the embedding layer by first specifying the dimensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYMIiYD1fhfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim=10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15AZubKJgBr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= Sequential()\n",
        "model.add(Embedding(voc_size, 10, input_length=sent_length))\n",
        "model.compile(\"adam\", \"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3abgSVwgYCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "78ac244b-c435-4e9b-f1a5-6905e7178e2f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 8, 10)             100000    \n",
            "=================================================================\n",
            "Total params: 100,000\n",
            "Trainable params: 100,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWRQ8w9zgbpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to visualise the embedded docs use the following"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqX3vmXQghx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "190d7848-aa21-4bd2-8aa4-3763a8afeae7"
      },
      "source": [
        "print(model.predict(embedded_docs))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [ 0.00010144 -0.02305658 -0.00533779  0.02455579  0.01535118\n",
            "    0.03841901 -0.02659302  0.01966382 -0.02032864 -0.03127053]\n",
            "  [-0.02546822 -0.00756079 -0.01709424  0.02064774 -0.02138015\n",
            "   -0.01184344  0.04587782  0.03234509  0.02728191  0.04127885]\n",
            "  [ 0.01703197 -0.00676344  0.01575842  0.02993752  0.01173741\n",
            "    0.02881073 -0.00572356 -0.03846942  0.01307753 -0.0162832 ]\n",
            "  [-0.04157982  0.02239454  0.02086986 -0.01517365  0.00215524\n",
            "   -0.02604993  0.00931741 -0.01557238 -0.0498278  -0.0324008 ]]\n",
            "\n",
            " [[-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [ 0.00010144 -0.02305658 -0.00533779  0.02455579  0.01535118\n",
            "    0.03841901 -0.02659302  0.01966382 -0.02032864 -0.03127053]\n",
            "  [-0.02546822 -0.00756079 -0.01709424  0.02064774 -0.02138015\n",
            "   -0.01184344  0.04587782  0.03234509  0.02728191  0.04127885]\n",
            "  [ 0.01703197 -0.00676344  0.01575842  0.02993752  0.01173741\n",
            "    0.02881073 -0.00572356 -0.03846942  0.01307753 -0.0162832 ]\n",
            "  [ 0.0258142  -0.04364357 -0.01480713  0.03813492 -0.03405927\n",
            "    0.02420861  0.0389722   0.01703772  0.02480297 -0.03636125]]\n",
            "\n",
            " [[-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [ 0.00010144 -0.02305658 -0.00533779  0.02455579  0.01535118\n",
            "    0.03841901 -0.02659302  0.01966382 -0.02032864 -0.03127053]\n",
            "  [-0.00391587 -0.02380355  0.01348266 -0.02137991  0.0178736\n",
            "   -0.02124974  0.03070631  0.03602761  0.02708013 -0.04665517]\n",
            "  [ 0.01703197 -0.00676344  0.01575842  0.02993752  0.01173741\n",
            "    0.02881073 -0.00572356 -0.03846942  0.01307753 -0.0162832 ]\n",
            "  [ 0.00455265  0.01918883  0.04542274 -0.03661009 -0.00179446\n",
            "   -0.0176847   0.02184988 -0.01004326 -0.02537289  0.04299985]]\n",
            "\n",
            " [[-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.00558288 -0.02479277 -0.00447394  0.01455102  0.03455775\n",
            "   -0.00284654 -0.00089614 -0.01429679 -0.00175854 -0.01669195]\n",
            "  [ 0.03204248  0.03936491 -0.04508488  0.0323212   0.03408951\n",
            "   -0.01938468  0.01814337 -0.04586644 -0.04930113  0.02822454]\n",
            "  [-0.02068706 -0.01871489 -0.01646701 -0.04316294  0.00416797\n",
            "    0.00509279  0.00315337  0.00659706  0.02674289 -0.01566184]\n",
            "  [-0.01965784  0.01573754 -0.03134006 -0.01551475 -0.04829615\n",
            "   -0.01102633  0.04240138 -0.01040311  0.00456399 -0.01897423]\n",
            "  [-0.03822954  0.04142134 -0.04223121  0.01653555  0.02975409\n",
            "    0.00942492 -0.04231211 -0.00701692 -0.04794573  0.03143898]]\n",
            "\n",
            " [[-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.00558288 -0.02479277 -0.00447394  0.01455102  0.03455775\n",
            "   -0.00284654 -0.00089614 -0.01429679 -0.00175854 -0.01669195]\n",
            "  [ 0.03204248  0.03936491 -0.04508488  0.0323212   0.03408951\n",
            "   -0.01938468  0.01814337 -0.04586644 -0.04930113  0.02822454]\n",
            "  [-0.02068706 -0.01871489 -0.01646701 -0.04316294  0.00416797\n",
            "    0.00509279  0.00315337  0.00659706  0.02674289 -0.01566184]\n",
            "  [-0.01965784  0.01573754 -0.03134006 -0.01551475 -0.04829615\n",
            "   -0.01102633  0.04240138 -0.01040311  0.00456399 -0.01897423]\n",
            "  [ 0.03195221  0.01438738  0.02028766 -0.01059159 -0.04613549\n",
            "    0.01610838  0.03049045 -0.0361599  -0.03522104  0.03849142]]\n",
            "\n",
            " [[-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.00080927 -0.04594452  0.01876937 -0.00712287 -0.04828348\n",
            "    0.03833742 -0.02915984 -0.01274642  0.01392602 -0.04852151]\n",
            "  [ 0.00010144 -0.02305658 -0.00533779  0.02455579  0.01535118\n",
            "    0.03841901 -0.02659302  0.01966382 -0.02032864 -0.03127053]\n",
            "  [-0.00396656 -0.03872276  0.00398006  0.00647407  0.02117154\n",
            "   -0.02184384 -0.03395321 -0.01327367  0.03575263  0.03838359]\n",
            "  [ 0.01703197 -0.00676344  0.01575842  0.02993752  0.01173741\n",
            "    0.02881073 -0.00572356 -0.03846942  0.01307753 -0.0162832 ]\n",
            "  [-0.00392344  0.01445076  0.00660111 -0.00328378 -0.03759469\n",
            "    0.03448795 -0.02612736  0.02352731 -0.0348606   0.03233815]]\n",
            "\n",
            " [[-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326\n",
            "   -0.00164687 -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            "  [-0.04340856 -0.0445364   0.04618846 -0.03256075  0.00621735\n",
            "   -0.00484685  0.0073704   0.00695799  0.03864337 -0.00380426]\n",
            "  [-0.03154775 -0.02851179 -0.01896708  0.03293708 -0.00193166\n",
            "    0.03970212 -0.00504204  0.00400045 -0.04696629 -0.03006487]\n",
            "  [ 0.02795482  0.03398385  0.00081419 -0.03462069 -0.04580579\n",
            "    0.00216714  0.01021319  0.00182819  0.04511689  0.04810952]\n",
            "  [-0.01965784  0.01573754 -0.03134006 -0.01551475 -0.04829615\n",
            "   -0.01102633  0.04240138 -0.01040311  0.00456399 -0.01897423]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGEXmnPlgwBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88f3d7f7-a542-4449-831a-370aea25c640"
      },
      "source": [
        "embedded_docs[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 7371,  713, 3825,   87], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZgtGCgEhaRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#so here it basically means that the word with the resepective indexes will gt converted into a 10 dimensional vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n7FVjjDgwT1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e0b6f909-924a-41dd-c528-ddd0cb9e40b7"
      },
      "source": [
        "print(model.predict(embedded_docs)[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326 -0.00164687\n",
            "  -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            " [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326 -0.00164687\n",
            "  -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            " [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326 -0.00164687\n",
            "  -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            " [-0.0033476  -0.0451025   0.00142052  0.04966414 -0.03840326 -0.00164687\n",
            "  -0.00499056 -0.04337609  0.02201051  0.01279452]\n",
            " [ 0.00010144 -0.02305658 -0.00533779  0.02455579  0.01535118  0.03841901\n",
            "  -0.02659302  0.01966382 -0.02032864 -0.03127053]\n",
            " [-0.02546822 -0.00756079 -0.01709424  0.02064774 -0.02138015 -0.01184344\n",
            "   0.04587782  0.03234509  0.02728191  0.04127885]\n",
            " [ 0.01703197 -0.00676344  0.01575842  0.02993752  0.01173741  0.02881073\n",
            "  -0.00572356 -0.03846942  0.01307753 -0.0162832 ]\n",
            " [-0.04157982  0.02239454  0.02086986 -0.01517365  0.00215524 -0.02604993\n",
            "   0.00931741 -0.01557238 -0.0498278  -0.0324008 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4EZYwbqhywY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#so comparing the embedded docs at 0 has got converted into 10 dimension vector for each word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nerT1aZ-iIPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}